:PROPERTIES:
:ID:       dd7c615f-cd8b-426d-aec0-cfd3803437cc
:mtime:    20251105134236 20240812121129 20240215115043 20240215090823 20230125190111 20230125155927
:ctime:    20230125155927
:END:
#+TITLE: Python Profiling
#+FILETAGS: :python:profiling:


* ~timeit~

The [[https://docs.python.org/3/library/timeit.html][timeit]] library allows you to profile code and get a feel for where bottle-necks are.

A simple example of profiling is shown below, the two functions ~remove_common_values()~ do the same thing but which is
faster?

#+begin_src python
import numpy as np
import numpy.typing as npt
import timeit


arr1 = np.asarray([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8]])
arr2 = np.asarray([[2, 2], [4, 4], [6, 6], [8, 8]])
retain = np.asarray([[6, 6]])

def remove_common_values(arr1: npt.NDArray=arr1, arr2: npt.NDArray=arr2, retain: list = retain) -> np.array:
    set_arr2 = {tuple(row) for row in arr2}
    set_retain = {tuple(row) for row in retain}
    # Create a new filtered list while maintaining the order of the first array
    filtered_arr1 = []
    for coord in arr1:
        tup_coord = tuple(coord)
        if tup_coord not in set_arr2 or tup_coord in set_retain:
            filtered_arr1.append(coord)
    return np.asarray(filtered_arr1)
remove_common_values()

def remove_common_values_lc(arr1: npt.NDArray=arr1, arr2: npt.NDArray=arr2, retain: list = retain) -> np.array:
    set_arr2 = {tuple(row) for row in arr2}
    set_retain = {tuple(row) for row in retain}
    return np.asarray([tuple(coord) for coord in arr1 if tuple(coord) not in set_arr2 or tuple(coord) in set_retain])
remove_common_values_lc()

REPEATS = 1000000
NUMBER = 1
np.mean(timeit.Timer(remove_common_values).repeat(repeat=REPEATS, number=NUMBER))
np.mean(timeit.Timer(remove_common_values_lc).repeat(repeat=REPEATS, number=NUMBER))
#+end_src

Here is another worked example of running ~timeit~ on some simple functions.

#+begin_src python
import numpy as np
import numpy.typing as npt
import timeit
import statistics
import pandas as pd
import matplotlib.pyplot as plt

test_arrays = {"left": np.array([[0, 0, 0], [1, 1, 0], [0, 0, 0]]),
               "right": np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]]),
               "top": np.array([[0, 1, 0], [0, 1, 0], [0, 0, 0]]),
               "bottom" : np.array([[0, 0, 0], [0, 1, 0], [0, 1, 0]]),
               "big_not" : np.zeros((1000, 1000)),
               "big_top" : np.zeros((1000, 1000)),
               "big_bottom" : np.zeros((1000, 1000)),
               "big_left" : np.zeros((1000, 1000)),
               "big_right" : np.zeros((1000, 1000)),
               }
test_arrays["big_top"][0,50] = 1
test_arrays["big_bottom"][-1,50] = 1
test_arrays["big_left"][50,0] = 1
test_arrays["big_left"][50,-1] = 1

def check_missing_padding(smoothed_mask: npt.NDArray) -> bool:
    rows, cols = smoothed_mask.shape
    for r in range(rows):
        for c in range(cols):
            if smoothed_mask[r, c]:
                neighbors = smoothed_mask[r - 1 : r + 2, c - 1 : c + 2]
                if neighbors.shape != (3, 3):
                    # Grain pixel found on edge of image
                    return True
    # No grain pixels are touching the edge
    return False

def check_pixels_touching_border(smoothed_mask) -> bool:
    if np.sum(smoothed_mask[0, :]) > 0:
        return True
    if np.sum(smoothed_mask[-1, :]) >0:
        return True
    if np.sum(smoothed_mask[:, 0]) > 0:
        return True
    if np.sum(smoothed_mask[:, -1]) > 0:
        return True
    return False

def check_pixels_touching_border_any(smoothed_mask) -> bool:
    if smoothed_mask[0, :].any():
        return True
    if smoothed_mask[-1, :].any() > 0:
        return True
    if smoothed_mask[:, 0].any() > 0:
        return True
    if smoothed_mask[:, -1].any() > 0:
        return True
    return False

def check_any(mask: npt.NDArray) -> bool:
    return mask[:, 0].any() or mask[:, -1].any() or mask[0, :].any() or mask[-1, :].any()

def edges_grouped(mask):
    edges = np.concat((mask[0, :], mask[-1, :], mask[:, 0], mask[:, -1]))
    return edges.any()

timer_missing_padding = timeit.Timer(lambda: check_missing_padding(test_arrays["big_top"]))
timer_pixels_touching = timeit.Timer(lambda: check_pixels_touching_border(test_arrays["big_top"]))
timer_pixels_touching_any = timeit.Timer(lambda: check_pixels_touching_border_any(test_arrays["big_top"]))
timer_any = timeit.Timer(lambda: check_any(test_arrays["big_top"]))
timer_edges_grouped = timeit.Timer(lambda: edges_grouped(test_arrays["big_top"]))

def test_methods(timer: timeit.Timer, n_timeit = 1000000, n_trials=30, method="Test", array="something"):
    results = [timer.timeit(number=n_timeit) for _ in range(n_trials)]
    return pd.DataFrame.from_dict({"method": [method],
                                   "array": [array],
                                   "mean": [statistics.mean(results)],
                                   "std": [statistics.stdev(results)],
                                   "min": [min(results)],
                                   "max": [max(results)]})

kwargs = {"n_timeit": 100, "n_trials": 20}
results = pd.DataFrame()
counter = 0
for array in ["big_bottom", "big_left", "big_right", "big_top",]:
    timer_missing_padding = timeit.Timer(lambda: check_missing_padding(test_arrays[array]))
    timer_pixels_touching = timeit.Timer(lambda: check_pixels_touching_border(test_arrays[array]))
    timer_any = timeit.Timer(lambda: check_any(test_arrays[array]))
    _stats = test_methods(timer_missing_padding, method="All rows and cols", array=array, **kwargs)
    if counter == 0:
        results = _stats
        counter = 1
    else:
        results = pd.concat([results, _stats])
    _stats = test_methods(timer_pixels_touching, method="Just borders", array=array, **kwargs)
    results = pd.concat([results, _stats])
    _stats = test_methods(timer_pixels_touching_any, method="Just borders (any)", array=array, **kwargs)
    results = pd.concat([results, _stats])
    _stats = test_methods(timer_any, method="All any", array=array, **kwargs)
    results = pd.concat([results, _stats])
    _stats = test_methods(timer_edges_grouped, method="Edges grouped", array=array, **kwargs)
    results = pd.concat([results, _stats])

colours = {"All rows and cols": "red", "Just borders (sum)": "blue", "Just borders (any)": "green", "All any": "yellow",
           "Edges grouped": "purple"}
results["colour"] = results["method"].map(colours)
results.plot(x="label", y="mean", yerr="std", logy=True, kind="bar", color=results["colour"])
plt.xlabel("Algorithm (Edge touching)")
plt.ylabel("log(Mean Execution)")
plt.title("Comparison of Mean edge finding algorithms with Standard Deviation Error Bars")
plt.show()

# Look at the means across all methods
results[["method", "mean"]].groupby("method").mean()

#+end_src
* [[https://rse.shef.ac.uk/pando-python/][Performance Profiling and Optimisation (Python)]]

** Introduction to Profiling
+ Why profile?
+ Choosing profilers?
+ Which tests?

+ ~timeit~ returns total runtime for a block of code and is therefore more suited for benchmarking. Instead use
  ~time.monotinic()~ to capture the points at which functions start and finish.
+ Standard library ~cProfile~ with ~SnakeViz~ to profile.
+ Line level profiling can be done using ~line_profiler~ which limits the target through use of the ~@profile~
  decorator.
+ [[https://viztracer.readthedocs.io/en/latest/index.html][VizTracer]] visualises via timeline rather than hierarchical. Shows over tine

*** Selecting Test Cases (Exercise)
TopoStats has never been profiled would be nice to do so and so we've no idea about where time is spent in processing.
In order to profile we would need...

+ A selection of images to profile one at time.
+ Assess the whole process to find out which of the stages (loading/filtering/grain finding/grainstatistics/tracing) are
  the slowest.
+ Once those have been identified focus in on each of the modules to see if there are bottlenecks within each of those.

** Function Level Profiling

*** Call Stack

*** cProfile

Always available as part of the standard library, call in command line with.

** Line Level Profiling


** Optimisation

+ Optimisation can be detrimental if focussing on small efficiencies, but it shouldn't be ignored for the small number
  of areas where big gains can be gained. /Premature optimisation is the root of all evil/ - Donald Knuth.
+ Obfuscating code can be detrimental to future maintainability!
+ Important to have tests in place so that changes to code do not break things, important to have tests in place.

*** pytest Overview

+ May include a small test.

** Data Structures and Algorithms

** Minimise Python (NumPy/Pandas)


** Feedback
+ Distribute setup instructions before hand.
+ Consider not having the text up whilst talking to class, people tend to read it.
+ [Will] - better distinction between benchmarking and profiling.
+ Course focuses on ~cProfile~ and visualisation with ~SnakeVix~.

* Links

+ [[https://docs.python.org/3/library/profile.html][Python Profiling (Standard Library)]]
+ [[https://docs.python.org/3/library/profile.html#module-cProfile][cProfile]]
+ [[https://docs.python.org/3/library/profile.html#module-profile][profile]]
+ [[https://docs.python.org/3/library/profile.html#module-pstats][pstats]]
+ [[https://pypi.org/project/scalene/][Scalene]] ([[https://github.com/plasma-umass/scalene][GitHub]])
+ [[https://jiffyclub.github.io/snakeviz/][SnakeViz]]
+ [[https://viztracer.readthedocs.io/en/latest/index.html][VizTracer]]
